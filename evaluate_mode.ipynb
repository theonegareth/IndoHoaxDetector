{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aa9c36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--data DATA] [--text-col TEXT_COL]\n",
      "                             [--label-col LABEL_COL] [--model-path MODEL_PATH]\n",
      "                             [--vectorizer-path VECTORIZER_PATH]\n",
      "                             [--max-show MAX_SHOW]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=c:\\Users\\Gareth\\AppData\\Roaming\\jupyter\\runtime\\kernel-v32e8e43fb89fdd060b5dba03d303bbbf35cf96110.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "from typing import Tuple\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 1. CONFIG\n",
    "# =========================\n",
    "\n",
    "# Default paths (override via CLI args)\n",
    "DEFAULT_MODEL_PATH = \"logreg_model.pkl\"\n",
    "DEFAULT_VECTORIZER_PATH = \"tfidf_vectorizer.pkl\"\n",
    "\n",
    "# Expected labeled CSV columns:\n",
    "# For your case (preprocessed_data_FINAL_FINAL.csv):\n",
    "# - text_col: \"text_clean\"\n",
    "# - label_col: \"label_encoded\"  (0 = FAKTA, 1 = HOAX)\n",
    "DEFAULT_TEXT_COL = \"text_clean\"\n",
    "DEFAULT_LABEL_COL = \"label_encoded\"\n",
    "\n",
    "INT_TO_STRING_LABEL = {0: \"FAKTA\", 1: \"HOAX\"}\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2. LOADING UTILS\n",
    "# =========================\n",
    "\n",
    "def load_model_and_vectorizer(\n",
    "    model_path: str,\n",
    "    vectorizer_path: str,\n",
    "):\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"[ERROR] Model file not found: {model_path}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "    if not os.path.exists(vectorizer_path):\n",
    "        print(f\"[ERROR] Vectorizer file not found: {vectorizer_path}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(f\"[INFO] Loading model from: {model_path}\")\n",
    "    model = joblib.load(model_path)\n",
    "    print(f\"[INFO] Loading vectorizer from: {vectorizer_path}\")\n",
    "    vectorizer = joblib.load(vectorizer_path)\n",
    "    return model, vectorizer\n",
    "\n",
    "\n",
    "def load_labeled_data(\n",
    "    csv_path: str,\n",
    "    text_col: str,\n",
    "    label_col: str,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load labeled evaluation data.\n",
    "\n",
    "    Assumptions for your project:\n",
    "    - text_col = 'text_clean' (already preprocessed exactly as during training)\n",
    "    - label_col = 'label_encoded' (0 = FAKTA, 1 = HOAX)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"[ERROR] Labeled CSV not found: {csv_path}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(f\"[INFO] Loading labeled data from: {csv_path}\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    if text_col not in df.columns:\n",
    "        print(f\"[ERROR] Text column '{text_col}' not found. Available: {list(df.columns)}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    if label_col not in df.columns:\n",
    "        print(f\"[ERROR] Label column '{label_col}' not found. Available: {list(df.columns)}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    df = df[[text_col, label_col]].dropna()\n",
    "    if df.empty:\n",
    "        print(\"[ERROR] No valid rows after dropping NA in text/label.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    # For your file, label_encoded is already 0/1, so we keep as is\n",
    "    df = df.rename(columns={text_col: \"text\", label_col: \"true_label\"})\n",
    "\n",
    "    # Keep only rows with labels 0 or 1\n",
    "    before = len(df)\n",
    "    df = df[df[\"true_label\"].isin([0, 1])]\n",
    "    after = len(df)\n",
    "    if after == 0:\n",
    "        print(\"[ERROR] No rows with valid labels (0/1) after filtering.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "    if after < before:\n",
    "        print(f\"[INFO] Filtered out {before - after} rows with invalid label values.\", flush=True)\n",
    "\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3. EVALUATION LOGIC\n",
    "# =========================\n",
    "\n",
    "def evaluate_model_on_labeled(\n",
    "    df: pd.DataFrame,\n",
    "    model,\n",
    "    vectorizer,\n",
    "    max_examples_to_show: int = 5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate model on already-preprocessed texts.\n",
    "\n",
    "    IMPORTANT:\n",
    "    - We DO NOT re-clean or restem here because `text_clean` in your dataset\n",
    "      is assumed to already match what the vectorizer was trained on.\n",
    "    \"\"\"\n",
    "    print(\"[INFO] Using pre-cleaned text from dataset (no extra preprocessing).\")\n",
    "\n",
    "    # Vectorize using loaded TF-IDF (MUST use transform, not fit_transform)\n",
    "    print(\"[INFO] Vectorizing texts with existing TF-IDF...\")\n",
    "    X = vectorizer.transform(df[\"text\"])\n",
    "\n",
    "    # Predictions\n",
    "    print(\"[INFO] Running predictions...\")\n",
    "    probs = model.predict_proba(X)\n",
    "    preds = model.predict(X)\n",
    "    confidences = probs.max(axis=1)\n",
    "\n",
    "    df[\"pred_label\"] = preds\n",
    "    df[\"pred_str\"] = df[\"pred_label\"].map(INT_TO_STRING_LABEL)\n",
    "    df[\"true_str\"] = df[\"true_label\"].map(INT_TO_STRING_LABEL)\n",
    "    df[\"confidence\"] = confidences\n",
    "\n",
    "    # --- Metrics ---\n",
    "    print(\"\\n===== CORE METRICS =====\")\n",
    "    acc = accuracy_score(df[\"true_label\"], df[\"pred_label\"])\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "\n",
    "    print(\"\\nClassification report (macro/micro F1, per-class metrics):\")\n",
    "    print(\n",
    "        classification_report(\n",
    "            df[\"true_label\"],\n",
    "            df[\"pred_label\"],\n",
    "            target_names=[\"FAKTA(0)\", \"HOAX(1)\"],\n",
    "            digits=4,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(\"Confusion matrix [[TN, FP], [FN, TP]]:\")\n",
    "    print(confusion_matrix(df[\"true_label\"], df[\"pred_label\"]))\n",
    "\n",
    "    # --- Error buckets ---\n",
    "    fp = df[(df[\"true_label\"] == 0) & (df[\"pred_label\"] == 1)]\n",
    "    fn = df[(df[\"true_label\"] == 1) & (df[\"pred_label\"] == 0)]\n",
    "\n",
    "    print(f\"\\nTotal examples: {len(df)}\")\n",
    "    print(f\"False Positives (FAKTA→HOAX): {len(fp)}\")\n",
    "    print(f\"False Negatives (HOAX→FAKTA): {len(fn)}\")\n",
    "\n",
    "    # Show high-confidence mistakes for qualitative analysis\n",
    "    def show_examples(sub_df, title: str):\n",
    "        if sub_df.empty:\n",
    "            print(f\"\\nNo {title} examples.\")\n",
    "            return\n",
    "        print(f\"\\n===== {title} (up to {max_examples_to_show}) =====\")\n",
    "        sub_df_sorted = sub_df.sort_values(\"confidence\", ascending=False).head(max_examples_to_show)\n",
    "        for _, row in sub_df_sorted.iterrows():\n",
    "            snippet = str(row[\"text\"]).replace(\"\\n\", \" \")\n",
    "            if len(snippet) > 200:\n",
    "                snippet = snippet[:200] + \"...\"\n",
    "            print(\n",
    "                f\"- true={row['true_str']}, pred={row['pred_str']}, \"\n",
    "                f\"conf={row['confidence']:.3f} :: {snippet}\"\n",
    "            )\n",
    "\n",
    "    show_examples(fp, \"High-confidence False Positives\")\n",
    "    show_examples(fn, \"High-confidence False Negatives\")\n",
    "\n",
    "    print(\"\\n[INFO] Evaluation complete.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4. CLI\n",
    "# =========================\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=(\n",
    "            \"Evaluate IndoHoaxDetector (TF-IDF + Logistic Regression) on a labeled CSV \"\n",
    "            \"and print accuracy, F1, confusion matrix, and sample errors.\\n\"\n",
    "            \"Defaults are set for preprocessed_data_FINAL_FINAL.csv \"\n",
    "            \"(text_clean, label_encoded).\\n\"\n",
    "            \"If --data is not provided, it defaults to '../preprocessed_data_FINAL_FINAL.csv'.\"\n",
    "        )\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data\",\n",
    "        type=str,\n",
    "        default=\"../preprocessed_data_FINAL_FINAL.csv\",\n",
    "        help=(\n",
    "            \"Path to labeled CSV containing preprocessed text and ground-truth labels. \"\n",
    "            \"Default: ../preprocessed_data_FINAL_FINAL.csv\"\n",
    "        ),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--text-col\",\n",
    "        type=str,\n",
    "        default=DEFAULT_TEXT_COL,\n",
    "        help=f\"Name of text column in CSV (default: {DEFAULT_TEXT_COL}).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--label-col\",\n",
    "        type=str,\n",
    "        default=DEFAULT_LABEL_COL,\n",
    "        help=f\"Name of label column in CSV (default: {DEFAULT_LABEL_COL}).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model-path\",\n",
    "        type=str,\n",
    "        default=DEFAULT_MODEL_PATH,\n",
    "        help=f\"Path to saved model .pkl (default: {DEFAULT_MODEL_PATH}).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--vectorizer-path\",\n",
    "        type=str,\n",
    "        default=DEFAULT_VECTORIZER_PATH,\n",
    "        help=f\"Path to saved TF-IDF vectorizer .pkl (default: {DEFAULT_VECTORIZER_PATH}).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max-show\",\n",
    "        type=int,\n",
    "        default=5,\n",
    "        help=\"Max number of FP/FN examples to print for qualitative error analysis.\",\n",
    "    )\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5. ENTRYPOINTS\n",
    "# =========================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    CLI entrypoint (for running from a real terminal).\n",
    "    \"\"\"\n",
    "    args = parse_args()\n",
    "\n",
    "    model, vectorizer = load_model_and_vectorizer(\n",
    "        args.model_path,\n",
    "        args.vectorizer_path,\n",
    "    )\n",
    "    df = load_labeled_data(\n",
    "        csv_path=args.data,\n",
    "        text_col=args.text_col,\n",
    "        label_col=args.label_col,\n",
    "    )\n",
    "\n",
    "    evaluate_model_on_labeled(\n",
    "        df=df,\n",
    "        model=model,\n",
    "        vectorizer=vectorizer,\n",
    "        max_examples_to_show=args.max_show,\n",
    "    )\n",
    "\n",
    "\n",
    "def run_evaluation(\n",
    "    data_path: str = \"../preprocessed_data_FINAL_FINAL.csv\",\n",
    "    text_col: str = \"text_clean\",\n",
    "    label_col: str = \"label_encoded\",\n",
    "    model_path: str = \"logreg_model.pkl\",\n",
    "    vectorizer_path: str = \"tfidf_vectorizer.pkl\",\n",
    "    max_show: int = 5,\n",
    "):\n",
    "    \"\"\"\n",
    "    JUPYTER-FRIENDLY ENTRYPOINT.\n",
    "\n",
    "    Call this from a notebook to avoid argparse / ipykernel --f issues.\n",
    "\n",
    "    Example in a notebook cell (with notebook in the same folder as this file):\n",
    "\n",
    "        from evaluate_model import run_evaluation\n",
    "        run_evaluation()\n",
    "    \"\"\"\n",
    "    model, vectorizer = load_model_and_vectorizer(\n",
    "        model_path,\n",
    "        vectorizer_path,\n",
    "    )\n",
    "    df = load_labeled_data(\n",
    "        csv_path=data_path,\n",
    "        text_col=text_col,\n",
    "        label_col=label_col,\n",
    "    )\n",
    "\n",
    "    return evaluate_model_on_labeled(\n",
    "        df=df,\n",
    "        model=model,\n",
    "        vectorizer=vectorizer,\n",
    "        max_examples_to_show=max_show,\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
